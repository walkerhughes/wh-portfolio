{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "from openai import OpenAI\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./llm_prompts/page_2/initial_game_prompt.txt\", \"r\") as infile: \n",
    "    game_prompt_template = Template(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"portuguese\"\n",
    "session_state = dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = game_prompt_template.substitute(language=language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"openai_model\" not in session_state: \n",
    "    session_state[\"openai_model\"] = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"messages\" not in session_state: \n",
    "    session_state[\"messages\"] = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai_model': 'gpt-3.5-turbo',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': \"I am fluent in portuguese, and you are an expert at figurative language, cultural expressions, and idioms in the portuguese language.\\n\\nWe are playing a game in which the goal is for the player to score the most points. You, the master of ceremonies, will present the \\nplayer with a {} idiom or saying and give an example of it being used in a sentence to add context. The player has to guess \\nits correct meaning from one of three multiple-choice answers that you present. Users score 1 point for a correct answer.\\n\\nStart with easier questions and increase the difficulty as the player gets more correct. Make sure the correct answer alternates \\nbetween options A, B, or C. \\n\\nIf the user does not get the question correct the first try, DO NOT reveal the answer to them immediately. Instead, give them another try \\nto guess its meaning, providing a second example of the phrase being used in a sentence to add further context. If the player get's the \\nanswer correct on the second try, they get 0.5 points. If they get the answer wrong twice, you may reveal the correct meaning with a brief \\nexplanation of what the phrase means. Give the player a running point tally after each correct guess, or after you reveal the correct answer \\nto them if they guess incorrectly twice in a row.\\n\\nUse the following structure for your response, filling in your portion inside the <>: \\n\\nPhrase: <add phrase in portuguese> \\n\\nIn a Sentence: <give an example of it being used in a sentence>\\n\\nCan you guess what it means?\\n\\nA: <option a>\\n\\nB: <option b>\\n\\nC: <option c>\\n\\nLet's play!\"}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_chat = client.chat.completions.create(\n",
    "    model = session_state[\"openai_model\"],\n",
    "    messages = [\n",
    "        {\"role\": message[\"role\"], \n",
    "         \"content\": message[\"content\"]} \n",
    "         for message in session_state[\"messages\"]\n",
    "        ],\n",
    "    stream = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x110e73e90>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when stream = False\n",
    "# print(current_chat.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"\"\n",
    "for _ in current_chat: \n",
    "    chunk = _.choices[0].delta.content\n",
    "\n",
    "    if chunk is None: \n",
    "        continue\n",
    "    else: \n",
    "        response += chunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase: \"Matar dois coelhos com uma cajadada sÃ³\"\n",
      "\n",
      "In a Sentence: \"Se vocÃª estudar para o teste de matemÃ¡tica, vai matar dois coelhos com uma cajadada sÃ³: vai tirar uma boa nota e aprender o conteÃºdo.\"\n",
      "\n",
      "Can you guess what it means?\n",
      "\n",
      "A: To eat a lot of food\n",
      "B: To kill two birds with one stone\n",
      "C: To go for a walk in the park\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\"A\": None, \"B\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': None, 'B': None}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    'English': \"ðŸ‡ºðŸ‡¸\", \n",
    "    'Portuguese': \"ðŸ‡§ðŸ‡·\", \n",
    "    'Spanish': \"ðŸ‡²ðŸ‡½\",\n",
    "    'French': \"ðŸ‡«ðŸ‡·\",\n",
    "    'Italian': \"ðŸ‡®ðŸ‡¹\",\n",
    "    'German': \"ðŸ‡©ðŸ‡ª\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['English', 'Portuguese', 'Spanish', 'French', 'Italian', 'German']),\n",
       " dict_values(['ðŸ‡ºðŸ‡¸', 'ðŸ‡§ðŸ‡·', 'ðŸ‡²ðŸ‡½', 'ðŸ‡«ðŸ‡·', 'ðŸ‡®ðŸ‡¹', 'ðŸ‡©ðŸ‡ª']))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages.keys(), languages.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
