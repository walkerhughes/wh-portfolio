{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "import textwrap\n",
    "\n",
    "class YoutubeVideoRAG:\n",
    "    \"\"\"\n",
    "    class for querying youtube video transcripts with gpt 3.5 turbo using langchain\n",
    "\n",
    "    all user inputs are specified when instantiating the class with a list of video url's\n",
    "\n",
    "    users can then use the .answer_query method to ask questions\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key: str = \"\", video_urls: list = []):\n",
    "\n",
    "        self.video_urls = video_urls\n",
    "        self.api_key = api_key\n",
    "        self.final_docs = []\n",
    "        self.embeddings = OpenAIEmbeddings(openai_api_key = self.api_key)\n",
    "        self.chat = ChatOpenAI(\n",
    "            openai_api_key=self.api_key,\n",
    "            model_name=\"gpt-3.5-turbo\",\n",
    "            temperature=0.2\n",
    "        )\n",
    "        print(self.video_urls)\n",
    "        self.db = self.create_db_from_video_urls(self.video_urls)\n",
    "\n",
    "        self.system_template = \"\"\"\n",
    "            You are a helpful assistant answering questions about youtube videos based on their transcripts: {docs}\n",
    "\n",
    "            Only use factual information from the transcipt to answer the question. The answers you provide should be detailed but concise, \\\n",
    "            and understandable by someone who has not watched the Youtube video or read the transcript.\n",
    "\n",
    "            If you feel like you don't have enought information to answer the question, \\\n",
    "            repond with 'I don't have sufficient information to answer this question at the moment based on the transcript of this video alone.'\n",
    "        \"\"\"\n",
    "\n",
    "        self.human_template = \"Answer the following question: {question}\"\n",
    "\n",
    "    def create_db_from_video_urls(self, video_urls: list = []):\n",
    "\n",
    "        for video_url in video_urls:\n",
    "            try:\n",
    "                loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "                transcript = loader.load()\n",
    "                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "                docs = text_splitter.split_documents(transcript)\n",
    "                for _ in docs:\n",
    "                    self.final_docs.append(_)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        db = FAISS.from_documents(self.final_docs, self.embeddings)\n",
    "        return db\n",
    "\n",
    "    def print_response(self, response: str):\n",
    "        print(textwrap.fill(response, width=75))\n",
    "\n",
    "    def answer_query(self, query: str, k: int = 4):\n",
    "\n",
    "        def document_similarity_search(query: str = \"\", k: int = 4):\n",
    "            docs = self.db.similarity_search(query, k=k)\n",
    "            docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "            return docs_page_content\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(self.system_template),\n",
    "            HumanMessagePromptTemplate.from_template(self.human_template)\n",
    "        ])\n",
    "\n",
    "        docs_page_content = document_similarity_search(query = query, k = k)\n",
    "\n",
    "        chain = LLMChain(llm=self.chat, prompt=chat_prompt)\n",
    "        response = chain.run(question=query, docs=docs_page_content).replace(\"\\n\", \" \")\n",
    "        self.response = response\n",
    "        return self.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/watch?v=4t4YkHSTZbw&t=2s\"\n",
    "key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.youtube.com/watch?v=4t4YkHSTZbw&t=2s', 'https://www.youtube.com/watch?v=4t4YkHSTZbw&t=2s']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bot \u001b[38;5;241m=\u001b[39m \u001b[43mYoutubeVideoRAG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_urls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 34\u001b[0m, in \u001b[0;36mYoutubeVideoRAG.__init__\u001b[0;34m(self, api_key, video_urls)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[1;32m     29\u001b[0m     openai_api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m     30\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_urls)\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_db_from_video_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_urls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m    You are a helpful assistant answering questions about youtube videos based on their transcripts: \u001b[39m\u001b[38;5;132;01m{docs}\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124m    repond with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have sufficient information to answer this question at the moment based on the transcript of this video alone.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhuman_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer the following question: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[32], line 61\u001b[0m, in \u001b[0;36mYoutubeVideoRAG.create_db_from_video_urls\u001b[0;34m(self, video_urls)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m db\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/vectorstores.py:550\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    549\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:931\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    930\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m--> 931\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:888\u001b[0m, in \u001b[0;36mFAISS.__from\u001b[0;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m     index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatIP(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;66;03m# Default to L2, currently other metric types not initialized.\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m     index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatL2(\u001b[38;5;28mlen\u001b[39m(\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m    889\u001b[0m docstore \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocstore\u001b[39m\u001b[38;5;124m\"\u001b[39m, InMemoryDocstore())\n\u001b[1;32m    890\u001b[0m index_to_docstore_id \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_to_docstore_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bot = YoutubeVideoRAG(api_key=key, video_urls=[url, url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
