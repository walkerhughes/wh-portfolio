{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import joblib \n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "from string import Template\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_language = \"Portuguese\"\n",
    "used_idioms = set()\n",
    "with open(\"./llm_prompts/page_2/json_prompt.txt\", \"r\") as infile: \n",
    "    json_prompt = Template(infile.read()) \n",
    "    json_prompt = json_prompt.substitute(\n",
    "        language = test_language, \n",
    "        used_idioms = used_idioms\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return a json object in the following format:\n",
      "{\n",
      "\"idiom\": <Portuguese idiom here>,\n",
      "\"context\": <a list of two Portuguese sentences using the idiom to give context for how it is typically used>,\n",
      "\"multiple_choice\": <a list of three options for the idiom's meaning in English here, but not literal translations of the idiom to English>,\n",
      "\"index\": <the numeric index of the correct option for the meaning of the idiom from the list with key \"multiple_choice\">\n",
      "}\n",
      "\n",
      "Do not use an idiom that is already in the following Python set: \n",
      "used_idioms = set()\n"
     ]
    }
   ],
   "source": [
    "print(json_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\": \"user\", \"content\": json_prompt}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idiom': 'Cair do cavalo e achar boné',\n",
       " 'context': ['Ontem, minha colega achou que era muito fácil passar na prova, mas hoje ela caiu do cavalo e achou o boné.',\n",
       "  'Os políticos do país estão prestes a cair do cavalo e achar o boné se não começarem a agir com mais responsabilidade.'],\n",
       " 'multiple_choice': ['To underestimate the difficulty of a situation',\n",
       "  'To make a fortunate discovery',\n",
       "  'To take advantage of a situation'],\n",
       " 'index': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = json.loads(chat.choices[0].message.content)\n",
    "\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_question(question_json):\n",
    "\n",
    "    question = \"Idiom: {}\\n\\nIn a sentence: {}\\n\\nAnswers:\\n\".format(\n",
    "        question_json[\"idiom\"],\n",
    "        question_json[\"context\"][0]\n",
    "    )\n",
    "\n",
    "    st.write(question)\n",
    "\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    button1_clicked = col1.button(question_json[\"multiple_choice\"][0])\n",
    "    button2_clicked = col2.button(question_json[\"multiple_choice\"][1])\n",
    "    button3_clicked = col3.button(question_json[\"multiple_choice\"][2])\n",
    "\n",
    "    if button1_clicked:\n",
    "        st.write(\"Button 1 was clicked\")\n",
    "    elif button2_clicked:\n",
    "        st.write(\"Button 2 was clicked\")\n",
    "    elif button3_clicked:\n",
    "        st.write(\"Button 3 was clicked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format_question(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_question(question_json):\n",
    "\n",
    "    question = \"Idiom: {}\\n\\nIn a sentence: {}\\n\\nAnswers:\\n\".format(\n",
    "        question_json[\"idiom\"],\n",
    "        question_json[\"context\"][0]\n",
    "    )\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_question(question_json = llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
